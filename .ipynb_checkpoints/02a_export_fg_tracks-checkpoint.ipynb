{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-nb'></a>\n",
    "\n",
    "# Music Recommender \n",
    "## Part 2a: Feature Store Creation - Tracks\n",
    "----\n",
    "\n",
    "This notebook creates a feature group for our tracks data to place in our feature store using the transformation instructions found in our `.flow` file. [Amazon SageMaker Feature Store](https://www.youtube.com/watch?v=pEg5c6d4etI) is a fully managed, purpose-built repository to store, update, retrieve, and share machine learning (ML) features.\n",
    "\n",
    "Features are the attributes or properties models use during training and inference to make predictions. For example, in a ML application that recommends a music playlist, features could include song ratings, which songs were listened to previously, and how long songs were listened to. The accuracy of a ML model is based on a precise set and composition of features. Often, these features are used repeatedly by multiple teams training multiple models. And whichever feature set was used to train the model needs to be available to make real-time predictions (inference). Keeping a single source of features that is consistent and up-to-date across these different access patterns is a challenge as most organizations keep two different feature stores, one for training and one for inference.\n",
    "\n",
    "Amazon SageMaker Feature Store is a purpose-built repository where you can store and access features so itâ€™s much easier to name, organize, and reuse them across teams. SageMaker Feature Store provides a unified store for features during training and real-time inference without the need to write additional code or create manual processes to keep features consistent. SageMaker Feature Store keeps track of the metadata of stored features (e.g. feature name or version number) so that you can query the features for the right attributes in batches or in real time using Amazon Athena, an interactive query service. SageMaker Feature Store also keeps features updated, because as new data is generated during inference, the single repository is updated so new features are always available for models to use during training and inference.\n",
    "\n",
    "\n",
    "----\n",
    "### Contents\n",
    "- [Overview](00_overview_arch_data.ipynb)\n",
    "- [Part 1: Data Prep using Data Wrangler](01_music_dataprep.flow)\n",
    "- [Part 2a: Feature Store Creation - Tracks](02a_export_fg_tracks.ipynb)\n",
    "    - [Define Feature Group](#02a-define-fg)\n",
    "    - [Configure Feature Group](#02a-config-fg)\n",
    "    - [Initialize & Create Feature Group](#02a-init-create-fg)\n",
    "    - [Inputs and Outputs](#02a-input-output)\n",
    "    - [Upload flow file](#02a-upload-flow)\n",
    "    - [Run Processing Job](#02a-run-job)\n",
    "- [Part 2b: Feature Store Creation - User Preferences](02b_export_fg_5star_features.ipynb)\n",
    "- [Part 2c: Feature Store Creation - Ratings](02c_fg_create_ratings.ipynb)\n",
    "- [Part 3: Train Model with Debugger Hooks. Set Artifacts and Register Model.](03_train_model_lineage_registry_debugger.ipynb)\n",
    "- [Part 4: Deploy Model & Inference using Online Feature Store](04_deploy_infer_explain.ipynb)\n",
    "- [Part 5: Model Monitor](05_model_monitor.ipynb)\n",
    "- [Part 6: SageMaker Pipelines](06_pipeline.ipynb)\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Quick Start </strong>\n",
    "To save your processed data to feature store, <strong><a style=\"color: #0397a7 \" href=\"#Create-Feature-Group\">\n",
    "    <u>Click here to create a feature group</u></a> and follow the instruction to run a SageMaker processing job.\n",
    "</strong>\n",
    "</div>\n",
    "\n",
    "This notebook uses Amazon SageMaker Feature Store (Feature Store) to create a feature group, \n",
    "executes your Data Wrangler Flow `00_music_dataprep.flow` on the entire dataset using a SageMaker \n",
    "Processing Job and ingest processed data to Feature Store. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "prefix             -> 'music-recommendation'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Group\n",
    "\n",
    "_What is a feature group_\n",
    "\n",
    "A single feature corresponds to a column in your dataset. A feature group is a predefined schema for a \n",
    "collection of features - each feature in the feature group has a specified data type and name. \n",
    "A single record in a feature group corresponds to a row in your dataframe. A feature store is a \n",
    "collection of feature groups. To learn more about SageMaker Feature Store, see \n",
    "[Amazon Feature Store Documentation](http://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-define-fg'></a>\n",
    "\n",
    "### Define Feature Group \n",
    "##### [back to top](#02a-nb)\n",
    "----\n",
    "Select Record identifier and Event time feature name. These are required parameters for feature group\n",
    "creation.\n",
    "* **Record identifier name** is the name of the feature defined in the feature group's feature definitions \n",
    "whose value uniquely identifies a Record defined in the feature group's feature definitions.\n",
    "* **Event time feature name** is the name of the EventTime feature of a Record in FeatureGroup. An EventTime \n",
    "is a timestamp that represents the point in time when a new event occurs that corresponds to the creation or \n",
    "update of a Record in the FeatureGroup. All Records in the FeatureGroup must have a corresponding EventTime.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡Record identifier and Event time feature name are required \n",
    "for feature group. After filling in the values, you can choose <b>Run Selected Cell and All Below</b> \n",
    "from the Run Menu from the menu bar. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker boto3 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading : \n",
      "\n",
      "{'music-rec': {'bucket': 'sagemaker-us-west-2-738335684114',\n",
      "               'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
      "               'prefix': 'music-recommendation',\n",
      "               'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
      "               'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv'}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "sys.path.insert(1, './code')\n",
    "from parameter_store import ParameterStore\n",
    "ps = ParameterStore()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : music-rec\n",
      "\n",
      "{'music-rec': {'bucket': 'sagemaker-us-west-2-738335684114',\n",
      "               'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
      "               'prefix': 'music-recommendation',\n",
      "               'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
      "               'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv'}}\n",
      "{'bucket': 'sagemaker-us-west-2-738335684114',\n",
      " 'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
      " 'prefix': 'music-recommendation',\n",
      " 'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
      " 'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv'}\n"
     ]
    }
   ],
   "source": [
    "parameters = ps.read('music-rec')\n",
    "pprint.pprint(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = parameters['bucket']\n",
    "prefix = parameters['prefix']\n",
    "model_path = parameters['model_path']\n",
    "ratings_data_source = parameters['ratings_data_source']\n",
    "tracks_data_source = parameters['tracks_data_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = 'trackId'\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = 'featureTimestamp'\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Definitions\n",
    "The following is a list of the feature names and feature types of the final dataset that will be produced \n",
    "when your data flow is used to process your input dataset. These are automatically generated from the \n",
    "step `Custom Pyspark` from `Source: Answers.Csv`. To save from a different step, go to Data Wrangler to \n",
    "select a new step to export.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Configurable Settings </strong>\n",
    "\n",
    "1. You can select a subset of the features. By default all columns of the result dataframe will be used as \n",
    "features.\n",
    "2. You can change the Data Wrangler data type to one of the Feature Store supported types \n",
    "(<b>Integral</b>, <b>Fractional</b>, or <b>String</b>). The default type is set to <b>String</b>. \n",
    "This means that, if a column in your dataset is not a <b>float</b> or <b>long</b> type, it will default \n",
    "to <b>String</b> in your Feature Store.\n",
    "\n",
    "For <b>Event Time</b> features, make sure the format follows the feature store\n",
    "<strong>\n",
    "    <a style=\"color: #0397a7 \" href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-quotas.html#feature-store-data-types\">\n",
    "    <u>Event Time feature format</u>\n",
    "    </a>\n",
    "</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of the feature names and data types of the final dataset that will be produced when your data flow is used to process your input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"trackId\",\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"length\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"energy\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"acousticness\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"valence\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"speechiness\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"instrumentalness\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"liveness\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"tempo\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Folk\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Country\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Latin\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Jazz\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_RnB\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Reggae\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Rap\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Pop_Rock\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Electronic\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"genre_Blues\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"featureTimestamp\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"danceability\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the SDK input for those feature definitions. Some schema types in Data Wrangler are not \n",
    "supported by Feature Store. The following will create a default_FG_type set to String for these types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name=column_schema['name'], \n",
    "        feature_type=column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-config-fg'></a>\n",
    "\n",
    "## Configure Feature Group\n",
    "##### [back to top](#02a-nb)\n",
    "----\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Configurable Settings </strong>\n",
    "\n",
    "1. <b>feature_group_name</b>: name of the feature group.\n",
    "1. <b>feature_store_offline_s3_uri</b>: SageMaker FeatureStore writes the data in the OfflineStore of a FeatureGroup to a S3 location owned by you.\n",
    "1. <b>enable_online_store</b>: controls if online store is enabled. Enabling the online store allows quick access to the latest value for a Record via the GetRecord API.\n",
    "1. <b>iam_role</b>: IAM role for executing the processing job.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "import sagemaker \n",
    "# IAM role for executing the processing job.\n",
    "iam_role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group Name: track-features-20-21-27-19-43cfaf71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# You can configure this with your own bucket name, e.g.\n",
    "# bucket = <my-own-storage-bucket>\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# flow name and an unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = \"01_music_dataprep\"\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "\n",
    "model_path\n",
    "\n",
    "# feature group name, with flow_name and an unique id. You can give it a customized name\n",
    "feature_group_name = f'track-features-{flow_export_id}'\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# SageMaker FeatureStore writes the data in the OfflineStore of a FeatureGroup to a \n",
    "# S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + bucket\n",
    "\n",
    "# controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a Record via the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Params : \n",
      "\n",
      "{'flow_export_id': '20-21-27-19-43cfaf71'}\n"
     ]
    }
   ],
   "source": [
    "ps.add({'flow_export_id': flow_export_id}, namespace='music-rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : music-rec\n",
      "\n",
      "{'music-rec': {'bucket': 'sagemaker-us-west-2-738335684114',\n",
      "               'flow_export_id': '20-21-27-19-43cfaf71',\n",
      "               'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
      "               'prefix': 'music-recommendation',\n",
      "               'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
      "               'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv'}}\n"
     ]
    }
   ],
   "source": [
    "parasm = ps.read('music-rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Params : \n",
      "\n",
      "{'dw_ecrlist': {'region': {'us-east-2': '415577184552',\n",
      "                           'us-west-1': '926135532090',\n",
      "                           'us-west-2': '174368400705'}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20-21-27-19-43cfaf71'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_ecrlist = {\n",
    "    'region':{'us-west-2':'174368400705',\n",
    "              'us-east-2':'415577184552',\n",
    "              'us-west-1':'926135532090'\n",
    "             }\n",
    "}\n",
    "\n",
    "\n",
    "ps.add({'dw_ecrlist': dw_ecrlist}, namespace='music-rec')\n",
    "\n",
    "\n",
    "flow_export_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Params : \n",
      "\n",
      "{'fg_name_tracks': 'track-features-20-21-27-19-43cfaf71'}\n",
      "track-features-20-21-27-19-43cfaf71\n"
     ]
    }
   ],
   "source": [
    "fg_name_tracks = feature_group_name\n",
    "\n",
    "ps.add({'fg_name_tracks': fg_name_tracks}, namespace='music-rec')\n",
    "\n",
    "print(fg_name_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-init-create-fg'></a>\n",
    "\n",
    "### Initialize & Create Feature Group\n",
    "##### [back to top](#02a-nb)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Boto3 session that is required to create feature group\n",
    "import boto3\n",
    "from sagemaker.session import Session\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature group is initialized and created below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature Group track-features-20-21-27-19-43cfaf71\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, sagemaker_session=feature_store_session, feature_definitions=feature_definitions)\n",
    "\n",
    "# only create feature group if it doesn't already exist\n",
    "try:\n",
    "    sagemaker_client.describe_feature_group(FeatureGroupName=feature_group_name, NextToken='string')\n",
    "    print(\"Feature Group {0} already exists. Using {0}\".format(feature_group_name))\n",
    "except Exception as e:\n",
    "    error = e.response.get('Error').get('Code')\n",
    "    if error == \"ResourceNotFound\":\n",
    "        print(\"Creating Feature Group {}\".format(feature_group_name))\n",
    "        feature_group.create(\n",
    "            s3_uri=feature_store_offline_s3_uri,\n",
    "            record_identifier_name=record_identifier_feature_name,\n",
    "            event_time_feature_name=event_time_feature_name,\n",
    "            role_arn=iam_role,\n",
    "            enable_online_store=enable_online_store\n",
    "        )\n",
    "    if error == 'ResourceInUse':\n",
    "        print(\"Feature Group {0} already exists. Using {0}\".format(feature_group_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the Feature Store API to create the feature group and wait until it is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup track-features-20-21-27-19-43cfaf71 successfully created.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise SystemExit(f\"Failed to create feature group {feature_group.name}: {status}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the feature group is created, You will use a processing job to process your \n",
    "        data at scale and ingest the transformed data into this feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-input-output'></a>\n",
    "\n",
    "## Inputs and Outputs\n",
    "##### [back to top](#02a-nb)\n",
    "----\n",
    "\n",
    "The below settings configure the inputs and outputs for the flow export.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Configurable Settings </strong>\n",
    "\n",
    "In <b>Input - Source</b> you can configure the data sources that will be used as input by Data Wrangler\n",
    "\n",
    "1. For S3 sources, configure the source attribute that points to the input S3 prefixes\n",
    "2. For all other sources, configure attributes like query_string, database in the source's \n",
    "<b>DatasetDefinition</b> object.\n",
    "\n",
    "If you modify the inputs the provided data must have the same schema and format as the data used in the Flow. \n",
    "You should also re-execute the cells in this section if you have modified the settings in any data sources.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "\n",
    "data_sources = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input - S3 Source: tracks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources.append(ProcessingInput(\n",
    "    source=f\"{tracks_data_source}\", # You could override this to point to another dataset on S3\n",
    "    destination=\"/opt/ml/processing/tracks.csv\",\n",
    "    input_name=\"tracks.csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input - S3 Source: ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources.append(ProcessingInput(\n",
    "    source=f\"{ratings_data_source}\", # You could override this to point to another dataset on S3\n",
    "    destination=\"/opt/ml/processing/ratings.csv\",\n",
    "    input_name=\"ratings.csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output: Feature Store \n",
    "\n",
    "Below are the inputs required by the SageMaker Python SDK to launch a processing job with feature store as an output. Notice the `output_name` variable below; this ID is found within the `.flow` file at the node point you want to capture transformations up to. The `.flow` file contains instructions for SageMaker Data Wrangler to know where to look for data and how to transform it. Each data transformation action is associated with a node and therefore a node ID. Using the associated node ID + output name tells SageMaker up to what point in the transformation process you want to export to a feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import FeatureStoreOutput\n",
    "\n",
    "# Output name is auto-generated from the select node's ID + output name from the .flow file\n",
    "output_name = \"d0d4f05a-3031-4438-867b-c5fd033d6c15.default\"\n",
    "\n",
    "processing_job_output = ProcessingOutput(\n",
    "    output_name=output_name,\n",
    "    app_managed=True,\n",
    "    feature_store_output=FeatureStoreOutput(feature_group_name=feature_group_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-upload-flow'></a>\n",
    "\n",
    "## Upload Flow to S3\n",
    "##### [back to top](#02a-nb)\n",
    "----\n",
    "To use the Data Wrangler as an input to the processing job,  first upload your flow file to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading flow file from current notebook working directory: /root/blogs/music-rec\n",
      "Updating Params : \n",
      "\n",
      "{'flow_s3_uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow'}\n",
      "Data Wrangler flow 01_music_dataprep.flow uploaded to s3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# name of the flow file which should exist in the current notebook working directory\n",
    "flow_file_name = \"01_music_dataprep.flow\"\n",
    "\n",
    "# Load .flow file from current notebook working directory \n",
    "!echo \"Loading flow file from current notebook working directory: $PWD\"\n",
    "\n",
    "with open(flow_file_name) as f:\n",
    "    flow = json.load(f)\n",
    "\n",
    "# Upload flow to S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_client.upload_file(flow_file_name, bucket, f\"{prefix}/data_wrangler_flows/{flow_export_name}.flow\")\n",
    "\n",
    "flow_s3_uri = f\"s3://{bucket}/{prefix}/data_wrangler_flows/{flow_export_name}.flow\"\n",
    "\n",
    "\n",
    "ps.add({'flow_s3_uri': flow_s3_uri}, namespace='music-rec')\n",
    "\n",
    "\n",
    "print(f\"Data Wrangler flow {flow_file_name} uploaded to {flow_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Wrangler Flow is also provided to the Processing Job as an input source which we configure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input - Flow: 01_music_dataprep.flow\n",
    "flow_input = ProcessingInput(\n",
    "    source=flow_s3_uri,\n",
    "    destination=\"/opt/ml/processing/flow\",\n",
    "    input_name=\"flow\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02a-run-job'></a>\n",
    "\n",
    "# Run Processing Job \n",
    "##### [back to top](#02a-nb)\n",
    "----\n",
    "## Job Configurations\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Configurable Settings </strong>\n",
    "\n",
    "You can configure the following settings for Processing Jobs. If you change any configurations you will \n",
    "need to re-execute this and all cells below it by selecting the Run menu above and click \n",
    "<b>Run Selected Cells and All Below</b>\n",
    "\n",
    "1. IAM role for executing the processing job. \n",
    "2. A unique name of the processing job. Give a unique name every time you re-execute processing jobs\n",
    "3. Data Wrangler Container URL.\n",
    "4. Instance count, instance type and storage volume size in GB.\n",
    "5. Content type for each output. Data Wrangler supports CSV as default and Parquet.\n",
    "6. Network Isolation settings\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71\n"
     ]
    }
   ],
   "source": [
    "# Unique processing job name. Give a unique name every time you re-execute processing jobs\n",
    "#processing_job_name = \"dw-flow-proc-music-rec-{}-{}\".format(flow_export_id, str(uuid.uuid4())[:8])\n",
    "\n",
    "processing_job_name = \"dw-flow-proc-music-rec-{}-{}\".format('tracks',flow_export_id)\n",
    "print (f\"{processing_job_name}\")\n",
    "\n",
    "# Data Wrangler Container URL.\n",
    "container_uri = f\"{dw_ecrlist['region'][region]}.dkr.ecr.{region}.amazonaws.com/sagemaker-data-wrangler-container:1.x\"\n",
    "\n",
    "# Processing Job Instance count and instance type.\n",
    "instance_count = 2\n",
    "instance_type = \"ml.m5.4xlarge\"\n",
    "\n",
    "# Size in GB of the EBS volume to use for storing data during processing\n",
    "volume_size_in_gb = 30\n",
    "\n",
    "# Content type for each output. Data Wrangler supports CSV as default and Parquet.\n",
    "output_content_type = \"CSV\"\n",
    "\n",
    "# Network Isolation mode; default is off\n",
    "enable_network_isolation = False\n",
    "\n",
    "# Output configuration used as processing job container arguments \n",
    "output_config = {\n",
    "    output_name: {\n",
    "        \"content_type\": output_content_type\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Processing Job\n",
    "\n",
    "To launch a Processing Job, you will use the SageMaker Python SDK to create a Processor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processing_job_name = \"data-wrangler-flow-processing-14-04-21-07-ad03dbf6-e0cc740a\"\n",
    "processing_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Processing Job: dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71\n",
      "\n",
      "Job Name:  dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71\n",
      "Inputs:  [{'InputName': 'flow', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow', 'LocalPath': '/opt/ml/processing/flow', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'tracks.csv', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv', 'LocalPath': '/opt/ml/processing/tracks.csv', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'ratings.csv', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv', 'LocalPath': '/opt/ml/processing/ratings.csv', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'd0d4f05a-3031-4438-867b-c5fd033d6c15.default', 'AppManaged': True, 'FeatureStoreOutput': {'FeatureGroupName': 'track-features-20-21-27-19-43cfaf71'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import Processor\n",
    "from sagemaker.network import NetworkConfig\n",
    "\n",
    "processor = Processor(\n",
    "    role=iam_role,\n",
    "    image_uri=container_uri,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size_in_gb=volume_size_in_gb,\n",
    "    network_config=NetworkConfig(enable_network_isolation=enable_network_isolation),\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# Run Processing Job if job not already previously ran\n",
    "\n",
    "\n",
    "try:\n",
    "    sagemaker_client.describe_processing_job(ProcessingJobName=processing_job_name)\n",
    "    print(\"Processing Job {0} already exists. Using {0}\".format(processing_job_name))\n",
    "except Exception as e:\n",
    "    error = e.response.get('Error').get('Code')\n",
    "    if error == \"ValidationException\":\n",
    "        print(\"Creating Processing Job: {}\".format(processing_job_name))\n",
    "        processor.run(\n",
    "            inputs=[flow_input] + data_sources, \n",
    "            outputs=[processing_job_output],\n",
    "            arguments=[f\"--output-config '{json.dumps(output_config)}'\"],\n",
    "            wait=False,\n",
    "            logs=False,\n",
    "            job_name=processing_job_name\n",
    "        )\n",
    "    else:\n",
    "        raise(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Status & S3 Output Location\n",
    "\n",
    "Below you wait for processing job to finish. If it finishes successfully, your feature group should be populated \n",
    "with transformed feature values. In addition the raw parameters used by the Processing Job will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................!CPU times: user 337 ms, sys: 32.6 ms, total: 370 ms\n",
      "Wall time: 6min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'flow',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow',\n",
       "    'LocalPath': '/opt/ml/processing/flow',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'tracks.csv',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv',\n",
       "    'LocalPath': '/opt/ml/processing/tracks.csv',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'ratings.csv',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
       "    'LocalPath': '/opt/ml/processing/ratings.csv',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'd0d4f05a-3031-4438-867b-c5fd033d6c15.default',\n",
       "    'FeatureStoreOutput': {'FeatureGroupName': 'track-features-20-21-27-19-43cfaf71'},\n",
       "    'AppManaged': True}]},\n",
       " 'ProcessingJobName': 'dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 2,\n",
       "   'InstanceType': 'ml.m5.4xlarge',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '174368400705.dkr.ecr.us-west-2.amazonaws.com/sagemaker-data-wrangler-container:1.x',\n",
       "  'ContainerArguments': ['--output-config \\'{\"d0d4f05a-3031-4438-867b-c5fd033d6c15.default\": {\"content_type\": \"CSV\"}}\\'']},\n",
       " 'NetworkConfig': {'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableNetworkIsolation': False},\n",
       " 'RoleArn': 'arn:aws:iam::738335684114:role/service-role/AmazonSageMaker-ExecutionRole-20201025T161024',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:738335684114:processing-job/dw-flow-proc-music-rec-tracks-20-21-27-19-43cfaf71',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ProcessingEndTime': datetime.datetime(2021, 6, 20, 21, 36, 12, 299000, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2021, 6, 20, 21, 33, 49, 91000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2021, 6, 20, 21, 36, 12, 303000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2021, 6, 20, 21, 29, 19, 825000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '3a77968a-6199-4ef1-a6a0-dce8c182dff4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3a77968a-6199-4ef1-a6a0-dce8c182dff4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2300',\n",
       "   'date': 'Sun, 20 Jun 2021 21:36:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "job_result = sess.wait_for_processing_job(processing_job_name)\n",
    "job_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing : \n",
      "\n",
      "{'music-rec': {'bucket': 'sagemaker-us-west-2-738335684114',\n",
      "               'dw_ecrlist': {'region': {'us-east-2': '415577184552',\n",
      "                                         'us-west-1': '926135532090',\n",
      "                                         'us-west-2': '174368400705'}},\n",
      "               'fg_name_tracks': 'track-features-20-21-27-19-43cfaf71',\n",
      "               'flow_export_id': '20-21-27-19-43cfaf71',\n",
      "               'flow_s3_uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow',\n",
      "               'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
      "               'prefix': 'music-recommendation',\n",
      "               'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
      "               'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv'}}\n"
     ]
    }
   ],
   "source": [
    "ps.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucket': 'sagemaker-us-west-2-738335684114',\n",
       " 'prefix': 'music-recommendation',\n",
       " 'tracks_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/tracks.csv',\n",
       " 'ratings_data_source': 's3://sagemaker-us-west-2-738335684114/music-recommendation/ratings.csv',\n",
       " 'model_path': 's://sagemaker-us-west-2-738335684114/music-recommendation/model.tar.gz',\n",
       " 'flow_export_id': '20-21-27-19-43cfaf71',\n",
       " 'dw_ecrlist': {'region': {'us-west-2': '174368400705',\n",
       "   'us-east-2': '415577184552',\n",
       "   'us-west-1': '926135532090'}},\n",
       " 'fg_name_tracks': 'track-features-20-21-27-19-43cfaf71',\n",
       " 'flow_s3_uri': 's3://sagemaker-us-west-2-738335684114/music-recommendation/data_wrangler_flows/flow-20-21-27-19-43cfaf71.flow'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket\n",
      "prefix\n",
      "tracks_data_source\n",
      "ratings_data_source\n",
      "model_path\n",
      "flow_export_id\n",
      "dw_ecrlist\n",
      "fg_name_tracks\n",
      "flow_s3_uri\n"
     ]
    }
   ],
   "source": [
    "for item in parameters:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('code.py', 'w') as filehandle:\n",
    "    for var in parameters:\n",
    "        filehandle.write(f\"{var} = parameter[\\'{var}\\']\\n\") #'%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynbname IPython --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_name():\n",
    "    \"\"\"Execute JS code to save Jupyter notebook name to variable `notebook_name`\"\"\"\n",
    "    from IPython.core.display import Javascript, display_javascript\n",
    "    js = Javascript(\"\"\"IPython.notebook.kernel.execute('notebook_name = \"' + IPython.notebook.notebook_name + '\"');\"\"\")\n",
    "    return display_javascript(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('notebook_name = \"' + IPython.notebook.notebook_name + '\"');"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "import json\n",
    "\n",
    "import ipynbname\n",
    "%matplotlib inline\n",
    "\n",
    "nb_fname = get_notebook_name()\n",
    "nb_fname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view newly created feature group in Studio, refer to [Use Amazon SageMaker Feature Store with Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-use-with-studio.html)\n",
    "for detailed guide. [Learn more about SageMaker Feature Store](https://github.com/aws/amazon-sagemaker-examples/tree/master/sagemaker-featurestore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
